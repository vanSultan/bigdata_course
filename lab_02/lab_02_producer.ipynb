{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Web UI: http://10.128.55.232:4041\n",
      "\n",
      "log4j file: /home/jovyan/conf/pyspark-log4j-producer_app.properties\n",
      "\n",
      "driver log file: /home/jovyan/logs/pyspark-producer_app.log\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import os\n",
    "import socket\n",
    "from pyspark import SparkConf, SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, length, when, col\n",
    "from pyspark.sql.types import BooleanType, IntegerType, LongType, StringType, ArrayType, FloatType, StructType, StructField\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.functions import PandasUDFType\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "\n",
    "# setting constants\n",
    "APP_NAME = \"producer_app\"\n",
    "NORMALIZED_APP_NAME = APP_NAME.replace('/', '_').replace(':', '_')\n",
    "\n",
    "APPS_TMP_DIR = os.path.join(os.getcwd(), \"tmp\")\n",
    "APPS_CONF_DIR = os.path.join(os.getcwd(), \"conf\")\n",
    "APPS_LOGS_DIR = os.path.join(os.getcwd(), \"logs\")\n",
    "LOG4J_PROP_FILE = os.path.join(APPS_CONF_DIR, \"pyspark-log4j-{}.properties\".format(NORMALIZED_APP_NAME))\n",
    "LOG_FILE = os.path.join(APPS_LOGS_DIR, 'pyspark-{}.log'.format(NORMALIZED_APP_NAME))\n",
    "EXTRA_JAVA_OPTIONS = \"-Dlog4j.configuration=file://{} -Dspark.hadoop.dfs.replication=1 -Dhttps.protocols=TLSv1.0,TLSv1.1,TLSv1.2,TLSv1.3\"\\\n",
    "    .format(LOG4J_PROP_FILE)\n",
    "\n",
    "LOCAL_IP = socket.gethostbyname(socket.gethostname())\n",
    "\n",
    "# preparing configuration files from templates\n",
    "for directory in [APPS_CONF_DIR, APPS_LOGS_DIR, APPS_TMP_DIR]:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('/opt'))\n",
    "template = env.get_template(\"pyspark_log4j.properties.template\")\n",
    "template\\\n",
    "    .stream(logfile=LOG_FILE)\\\n",
    "    .dump(LOG4J_PROP_FILE)\n",
    "\n",
    "# run spark\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(APP_NAME)\\\n",
    "    .master(\"k8s://https://10.32.7.103:6443\")\\\n",
    "    .config(\"spark.driver.host\", LOCAL_IP)\\\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\\\n",
    "    .config(\"spark.executor.instances\", \"2\")\\\n",
    "    .config(\"spark.executor.cores\", '3')\\\n",
    "    .config(\"spark.memory.fraction\", \"0.8\")\\\n",
    "    .config(\"spark.memory.storageFraction\", \"0.6\")\\\n",
    "    .config(\"spark.executor.memory\", '3g')\\\n",
    "    .config(\"spark.driver.memory\", \"3g\")\\\n",
    "    .config(\"spark.driver.maxResultSize\", \"1g\")\\\n",
    "    .config(\"spark.kubernetes.memoryOverheadFactor\", \"0.3\")\\\n",
    "    .config(\"spark.driver.extraJavaOptions\", EXTRA_JAVA_OPTIONS)\\\n",
    "    .config(\"spark.kubernetes.namespace\", \"szhumabaev-307617\")\\\n",
    "    .config(\"spark.kubernetes.driver.label.appname\", APP_NAME)\\\n",
    "    .config(\"spark.kubernetes.executor.label.appname\", APP_NAME)\\\n",
    "    .config(\"spark.kubernetes.container.image\", \"node03.st:5000/spark-executor:szhumabaev-307617\")\\\n",
    "    .config(\"spark.local.dir\", \"/tmp/spark\")\\\n",
    "    .config(\"spark.driver.extraClassPath\", \"/home/jovyan/shared-data/my-project-name-jar-with-dependencies.jar\")\\\n",
    "    .config(\"spark.executor.extraClassPath\", \"/home/jovyan/shared-data/my-project-name-jar-with-dependencies.jar\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.emptyDir.spark-local-dir-tmp-spark.mount.path\", \"/tmp/spark\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.emptyDir.spark-local-dir-tmp-spark.mount.readOnly\", \"false\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.hostPath.depdir.mount.path\", \"/home/jovyan/shared-data\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.hostPath.depdir.options.path\", \"/nfs/shared\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.hostPath.depdir.options.type\", \"Directory\")\\\n",
    "    .config(\"spark.kubernetes.executor.volumes.hostPath.depdir.mount.readOnly\", \"true\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "# printing important urls and pathes\n",
    "print(\"Web UI: {}\".format(spark.sparkContext.uiWebUrl))\n",
    "print(\"\\nlog4j file: {}\".format(LOG4J_PROP_FILE))\n",
    "print(\"\\ndriver log file: {}\".format(LOG_FILE))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "from kafka import KafkaProducer\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "posts_df = spark.read.json(\"/shared/bigdata20/followers_posts_api_final.json\")\\\n",
    "    .select(col(\"owner_id\").alias(\"user_id\"), \"text\", col(\"date\").alias(\"timestamp\"))\n",
    "# posts_df.show(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "posts_cnt = posts_df.count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "producer = KafkaProducer(bootstrap_servers=\"kafka-svc:9092\", value_serializer=str.encode)\n",
    "topic_name = \"main_topic\"\n",
    "\n",
    "for row in tqdm(posts_df.orderBy(\"timestamp\").rdd.toLocalIterator(), total=posts_cnt):\n",
    "    value = json.dumps(row.asDict(), ensure_ascii=False)\n",
    "    producer.send(topic_name, json.dumps(row.asDict(), ensure_ascii=False))\n",
    "    time.sleep(random.uniform(0.1, 2.))\n",
    "\n",
    "print(\"=\" * 80, \"\\nProducer finished\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}